{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IAS_NLP_Tutorials.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PCDnkS8Ncnl"
      },
      "source": [
        "# Institut des Algorithmes du Sénégal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRgN6q5St4Uz"
      },
      "source": [
        "# Tuto 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMvTwsj5NFQM",
        "outputId": "cbbe40a7-4ede-4f63-ad00-3aa6ca1ec302"
      },
      "source": [
        "# code by Institut des Algorithmes du Sénégal\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def make_batch():\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "\n",
        "    for sen in sentences:\n",
        "        word = sen.split() # space tokenizer\n",
        "        input = [word_dict[n] for n in word[:-1]] # create (1~n-1) as input\n",
        "        target = word_dict[word[-1]] # create (n) as target, We usually call this 'casual language model'\n",
        "\n",
        "        input_batch.append(input)\n",
        "        target_batch.append(target)\n",
        "\n",
        "    return input_batch, target_batch\n",
        "\n",
        "# Model\n",
        "class NNLM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NNLM, self).__init__()\n",
        "        self.C = nn.Embedding(n_class, m)\n",
        "        self.H = nn.Linear(n_step * m, n_hidden, bias=False)\n",
        "        self.d = nn.Parameter(torch.ones(n_hidden))\n",
        "        self.U = nn.Linear(n_hidden, n_class, bias=False)\n",
        "        self.W = nn.Linear(n_step * m, n_class, bias=False)\n",
        "        self.b = nn.Parameter(torch.ones(n_class))\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.C(X) # X : [batch_size, n_step, m]\n",
        "        X = X.view(-1, n_step * m) # [batch_size, n_step * m]\n",
        "        tanh = torch.tanh(self.d + self.H(X)) # [batch_size, n_hidden]\n",
        "        output = self.b + self.W(X) + self.U(tanh) # [batch_size, n_class]\n",
        "        return output\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    n_step = 2 # number of steps, n-1 in paper\n",
        "    n_hidden = 2 # number of hidden size, h in paper\n",
        "    m = 2 # embedding size, m in paper\n",
        "\n",
        "    sentences = [\"i like dog\", \"i love coffee\", \"i hate milk\"]\n",
        "\n",
        "    word_list = \" \".join(sentences).split()\n",
        "    word_list = list(set(word_list))\n",
        "    word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "    number_dict = {i: w for i, w in enumerate(word_list)}\n",
        "    n_class = len(word_dict)  # number of Vocabulary\n",
        "\n",
        "    model = NNLM()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    input_batch, target_batch = make_batch()\n",
        "    input_batch = torch.LongTensor(input_batch)\n",
        "    target_batch = torch.LongTensor(target_batch)\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(5000):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input_batch)\n",
        "\n",
        "        # output : [batch_size, n_class], target_batch : [batch_size]\n",
        "        loss = criterion(output, target_batch)\n",
        "        if (epoch + 1) % 1000 == 0:\n",
        "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Predict\n",
        "    predict = model(input_batch).data.max(1, keepdim=True)[1]\n",
        "\n",
        "    # Test\n",
        "    print([sen.split()[:2] for sen in sentences], '->', [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1000 cost = 0.293031\n",
            "Epoch: 2000 cost = 0.026870\n",
            "Epoch: 3000 cost = 0.007537\n",
            "Epoch: 4000 cost = 0.003010\n",
            "Epoch: 5000 cost = 0.001401\n",
            "[['i', 'like'], ['i', 'love'], ['i', 'hate']] -> ['dog', 'coffee', 'milk']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr4xcd__t7uB"
      },
      "source": [
        "# Tuto 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2aZAX6PNL_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4fc6dde-1ba7-471a-c2c4-33da12b4dcbf"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from autocorrect import spell\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import string"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz2srCJhwA3_"
      },
      "source": [
        "text = \"In this book authored by Sohom Ghosh and Dwight Gunning, we shall learnning how to pracess Natueral Language and extract insights from it. The first four chapter will introduce you to the basics of NLP. Later chapters will describe how to deal with complex NLP prajects. If you want to get early access of it, you should book your order now.\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymHsEu56wJzK",
        "outputId": "ac8ec36f-b0e3-45b9-d3cd-7487d1875b2d"
      },
      "source": [
        "words = word_tokenize(text)\n",
        "print(words[0:20])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['In', 'this', 'book', 'authored', 'by', 'Sohom', 'Ghosh', 'and', 'Dwight', 'Gunning', ',', 'we', 'shall', 'learnning', 'how', 'to', 'pracess', 'Natueral', 'Language', 'and']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDGFGstdwNKq",
        "outputId": "f91d4b9b-b8a1-4147-91c0-7e84a39862cb"
      },
      "source": [
        "corrected_sentence = \"\"\n",
        "corrected_word_list = []\n",
        "for wd in words:\n",
        "    if wd not in string.punctuation:\n",
        "        wd_c = spell(wd)\n",
        "        if wd_c != wd:\n",
        "            print(wd+\" has been corrected to: \"+wd_c)\n",
        "            corrected_sentence = corrected_sentence+\" \"+wd_c\n",
        "            corrected_word_list.append(wd_c)\n",
        "        else:\n",
        "            corrected_sentence = corrected_sentence+\" \"+wd\n",
        "            corrected_word_list.append(wd)\n",
        "    else:\n",
        "        corrected_sentence = corrected_sentence + wd\n",
        "        corrected_word_list.append(wd)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "Sohom has been corrected to: Show\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "Ghosh has been corrected to: Ghost\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "Dwight has been corrected to: Right\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "Gunning has been corrected to: Running\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "learnning has been corrected to: learning\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "pracess has been corrected to: process\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "Natueral has been corrected to: Natural\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "NLP has been corrected to: LP\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "NLP has been corrected to: LP\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "prajects has been corrected to: projects\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "Vk9GOfblwPnC",
        "outputId": "831e4efb-cbf8-4cf6-c48c-214cf0383a24"
      },
      "source": [
        "corrected_sentence"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' In this book authored by Show Ghost and Right Running, we shall learning how to process Natural Language and extract insights from it. The first four chapter will introduce you to the basics of LP. Later chapters will describe how to deal with complex LP projects. If you want to get early access of it, you should book your order now.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHrwwmMTwWlR",
        "outputId": "7daf2b18-0d95-4453-a75c-09d6fa719574"
      },
      "source": [
        "print(corrected_word_list[0:20])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['In', 'this', 'book', 'authored', 'by', 'Show', 'Ghost', 'and', 'Right', 'Running', ',', 'we', 'shall', 'learning', 'how', 'to', 'process', 'Natural', 'Language', 'and']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPx2-MgnwYes",
        "outputId": "7e717edf-bce8-4138-89cc-4ca6720bd1f6"
      },
      "source": [
        "print(nltk.pos_tag(corrected_word_list))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('In', 'IN'), ('this', 'DT'), ('book', 'NN'), ('authored', 'VBN'), ('by', 'IN'), ('Show', 'NNP'), ('Ghost', 'NNP'), ('and', 'CC'), ('Right', 'NNP'), ('Running', 'NNP'), (',', ','), ('we', 'PRP'), ('shall', 'MD'), ('learning', 'VB'), ('how', 'WRB'), ('to', 'TO'), ('process', 'VB'), ('Natural', 'NNP'), ('Language', 'NNP'), ('and', 'CC'), ('extract', 'JJ'), ('insights', 'NNS'), ('from', 'IN'), ('it', 'PRP'), ('.', '.'), ('The', 'DT'), ('first', 'JJ'), ('four', 'CD'), ('chapter', 'NN'), ('will', 'MD'), ('introduce', 'VB'), ('you', 'PRP'), ('to', 'TO'), ('the', 'DT'), ('basics', 'NNS'), ('of', 'IN'), ('LP', 'NNP'), ('.', '.'), ('Later', 'NNP'), ('chapters', 'NNS'), ('will', 'MD'), ('describe', 'VB'), ('how', 'WRB'), ('to', 'TO'), ('deal', 'VB'), ('with', 'IN'), ('complex', 'JJ'), ('LP', 'NNP'), ('projects', 'NNS'), ('.', '.'), ('If', 'IN'), ('you', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('get', 'VB'), ('early', 'JJ'), ('access', 'NN'), ('of', 'IN'), ('it', 'PRP'), (',', ','), ('you', 'PRP'), ('should', 'MD'), ('book', 'NN'), ('your', 'PRP$'), ('order', 'NN'), ('now', 'RB'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej63HjAlwaQI",
        "outputId": "1234f34f-e0dc-48c9-b10b-3a208227802e"
      },
      "source": [
        "# Downloads the data.\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "# Using the stopwords.\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "corrected_word_list_without_stopwords = []\n",
        "for wd in corrected_word_list:\n",
        "    if wd not in stop_words:\n",
        "        corrected_word_list_without_stopwords.append(wd)\n",
        "corrected_word_list_without_stopwords[:20]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In',\n",
              " 'book',\n",
              " 'authored',\n",
              " 'Show',\n",
              " 'Ghost',\n",
              " 'Right',\n",
              " 'Running',\n",
              " ',',\n",
              " 'shall',\n",
              " 'learning',\n",
              " 'process',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'extract',\n",
              " 'insights',\n",
              " '.',\n",
              " 'The',\n",
              " 'first',\n",
              " 'four',\n",
              " 'chapter']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQs_4Rw5wchP",
        "outputId": "9be51f29-3a29-4827-de90-b594897db554"
      },
      "source": [
        "stemmer = nltk.stem.PorterStemmer()\n",
        "corrected_word_list_without_stopwords_stemmed = []\n",
        "for wd in corrected_word_list_without_stopwords:\n",
        "    corrected_word_list_without_stopwords_stemmed.append(stemmer.stem(wd))\n",
        "corrected_word_list_without_stopwords_stemmed[:20]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In',\n",
              " 'book',\n",
              " 'author',\n",
              " 'show',\n",
              " 'ghost',\n",
              " 'right',\n",
              " 'run',\n",
              " ',',\n",
              " 'shall',\n",
              " 'learn',\n",
              " 'process',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'extract',\n",
              " 'insight',\n",
              " '.',\n",
              " 'the',\n",
              " 'first',\n",
              " 'four',\n",
              " 'chapter']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExpcyiCswrM3",
        "outputId": "74085a56-9c53-4a76-e00b-e91a0d8cf3d7"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "corrected_word_list_without_stopwords_lemmatized = []\n",
        "for wd in corrected_word_list_without_stopwords:\n",
        "    corrected_word_list_without_stopwords_lemmatized.append(lemmatizer.lemmatize(wd))\n",
        "corrected_word_list_without_stopwords_lemmatized[:20]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In',\n",
              " 'book',\n",
              " 'authored',\n",
              " 'Show',\n",
              " 'Ghost',\n",
              " 'Right',\n",
              " 'Running',\n",
              " ',',\n",
              " 'shall',\n",
              " 'learning',\n",
              " 'process',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'extract',\n",
              " 'insight',\n",
              " '.',\n",
              " 'The',\n",
              " 'first',\n",
              " 'four',\n",
              " 'chapter']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27NWZQ1EwtmR",
        "outputId": "94c90a1b-388d-4f1e-be4a-bd92f6ca9aa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(sent_tokenize(corrected_sentence))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' In this book authored by Show Ghost and Right Running, we shall learning how to process Natural Language and extract insights from it.', 'The first four chapter will introduce you to the basics of LP.', 'Later chapters will describe how to deal with complex LP projects.', 'If you want to get early access of it, you should book your order now.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaY4dlQPwwRO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}